import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler

import MetaTrader5 as mt5 # ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á 'MetaTrader5' ‡∏î‡πâ‡∏ß‡∏¢ pip install MetaTrader5
import json
from datetime import datetime

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô MT5 ---
symbol = "XAUUSDm"
timeframe = mt5.TIMEFRAME_H1  # ‡∏£‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
n_bars = 50000 # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á

print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö MT5...")
if not mt5.initialize():
    print("‚ùå MT5 initialize() failed. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ MT5 Terminal ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï Algo Trading.")
    quit()
print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MT5 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")

# --- ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {n_bars} ‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á {symbol} ({timeframe})...")
rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, n_bars)

if rates is None or len(rates) == 0:
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å MT5 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡πà‡∏≤‡∏á ({symbol}, {timeframe}).")
    mt5.shutdown()
    quit()

print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ {len(rates)} ‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô.")

# --- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame ---
df = pd.DataFrame(rates)
df['Date'] = pd.to_datetime(df['time'], unit='s')
df = df[['Date', 'open', 'high', 'low', 'close', 'tick_volume']]
df.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
df.set_index('Date', inplace=True)

print(f"\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å):\n{df.head()}")

# --- 2. Feature Engineering ---

print("\n‚öôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Features...")

# MA (Moving Averages)
df['MA5'] = df['Close'].rolling(5).mean()
df['MA10'] = df['Close'].rolling(10).mean()
df['MA20'] = df['Close'].rolling(20).mean()

# RSI (Relative Strength Index)
delta = df['Close'].diff()
gain = delta.where(delta > 0, 0.0)
loss = -delta.where(delta < 0, 0.0) # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ö‡∏ß‡∏Å‡πÄ‡∏™‡∏°‡∏≠
avg_gain = gain.rolling(window=14).mean()
avg_loss = loss.rolling(window=14).mean()

# ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÉ‡∏ô RSI
with np.errstate(divide='ignore', invalid='ignore'): # ‡∏õ‡∏¥‡∏î warning ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö division by zero
    rs = avg_gain / avg_loss
    df['RSI'] = 100 - (100 / (1 + rs))
df['RSI'].replace([np.inf, -np.inf], np.nan, inplace=True) # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà inf ‡∏î‡πâ‡∏ß‡∏¢ NaN

# Bollinger Bands
df['BB_Middle'] = df['Close'].rolling(20).mean()
df['BB_Std'] = df['Close'].rolling(20).std()
df['BB_Upper'] = df['BB_Middle'] + 2 * df['BB_Std']
df['BB_Lower'] = df['BB_Middle'] - 2 * df['BB_Std']

# MACD (Moving Average Convergence Divergence)
ema12 = df['Close'].ewm(span=12, adjust=False).mean()
ema26 = df['Close'].ewm(span=26, adjust=False).mean()
df['MACD'] = ema12 - ema26
df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
df['MACD_Diff'] = df['MACD'] - df['MACD_Signal'] # MACD - Signal (Momentum)

# Lag features (‡∏î‡∏π‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á) - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ Price Change
for i in range(1, 4):
    df[f'Close_lag{i}'] = df['Close'].shift(i)

# Price Change (absolute ‡πÅ‡∏•‡∏∞ percentage)
df['Price_Change'] = df['Close'] - df['Close_lag1']
df['Price_Change_Pct'] = df['Price_Change'] / df['Close_lag1']

# Bollinger Band Width
df['BB_Width'] = df['BB_Upper'] - df['BB_Lower']

# Candle Range
df['Candle_Range'] = df['High'] - df['Low']

# Volume Spike (‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö MA10 ‡∏Ç‡∏≠‡∏á Volume)
df['Volume_MA10'] = df['Volume'].rolling(window=10).mean()
df['Volume_Spike'] = df['Volume'] / df['Volume_MA10']
df['Volume_Change'] = df['Volume'].pct_change()

print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Features ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")
print(f"üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Features (5 ‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢):\n{df.tail()}")

# Target: ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ = 1, ‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô = 0
df['Target'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)
print(f"\nüéØ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏ô Target:\n{df['Target'].value_counts()}")


# --- 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ---

print("\nüßπ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•...")

print(f"üìå ‡∏Ç‡∏ô‡∏≤‡∏î DataFrame ‡∏Å‡πà‡∏≠‡∏ô dropna: {df.shape}")
print(f"üìå ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (NaN) ‡∏ï‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡πà‡∏≠‡∏ô dropna:\n{df.isnull().sum()[df.isnull().sum() > 0]}")

df.dropna(inplace=True)  # ‡∏•‡∏ö‡∏Ñ‡πà‡∏≤ NaN ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
print(f"‚úÖ ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á dropna: {df.shape}")

if df.empty:
    print("‚ùå DataFrame ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏ö NaN. ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô.")
    mt5.shutdown()
    exit()

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Features ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ
features = [
    'RSI', 'MACD', 'MACD_Diff',
    'BB_Upper', 'BB_Lower', 'BB_Width',
    'MA20', 'MA10', 'MA5', # ‡πÄ‡∏û‡∏¥‡πà‡∏° MA5 ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
    'Close_lag1', 'Close_lag2', 'Close_lag3', # ‡πÉ‡∏ä‡πâ lag 1, 2, 3
    'Price_Change', 'Price_Change_Pct',
    'Candle_Range', 'Volume_Change', 'Volume_Spike'
]

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏∏‡∏Å feature ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô DataFrame
missing_features = [f for f in features if f not in df.columns]
if missing_features:
    print(f"‚ùå Features ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {missing_features}")
    print("‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
    exit()

X = df[features]
y = df['Target']

# Normalize Features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("‚úÖ Features ‡∏ñ‡∏π‡∏Å Normalize ‡πÅ‡∏•‡πâ‡∏ß.")

# ‡πÅ‡∏ö‡πà‡∏á train/test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, shuffle=False, test_size=0.2)
print(f"‚úÖ ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Train ({len(X_train)} ‡πÅ‡∏ñ‡∏ß) ‡πÅ‡∏•‡∏∞ Test ({len(X_test)} ‡πÅ‡∏ñ‡∏ß) ‡πÅ‡∏•‡πâ‡∏ß.")

# --- 4. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost 3.0.1) ---

print("\nüöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost...")

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost 3.0.1 ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î eval_metric ‡πÉ‡∏ô Constructor ‡πÅ‡∏•‡∏∞ XGBoost ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Early Stopping ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ predict() ‡∏´‡∏£‡∏∑‡∏≠ predict_proba()
model_xgb = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss', # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î eval_metric ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
    scale_pos_weight=1.0, # ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏´‡∏≤‡∏Å target class ‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•
    n_estimators=1000,    # ‡∏ï‡∏±‡πâ‡∏á n_estimators ‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á‡∏û‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏´‡πâ Early Stopping ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    max_depth=4,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

# *** ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏•‡∏ö early_stopping_rounds ‡πÅ‡∏•‡∏∞ callbacks ‡∏≠‡∏≠‡∏Å ***
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost 3.0.1+ ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏™‡πà‡∏á eval_set ‡πÑ‡∏õ
# XGBoost ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Early Stopping ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å predict() ‡∏´‡∏£‡∏∑‡∏≠ predict_proba()
print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô XGBoost (‡πÉ‡∏ä‡πâ Early Stopping ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏ô XGBoost 3.0.1+)...")
model_xgb.fit(X_train, y_train,
              eval_set=[(X_test, y_test)], # ‡πÉ‡∏ä‡πâ X_test, y_test ‡πÄ‡∏õ‡πá‡∏ô validation set
              verbose=False # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å
             )
print("‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô XGBoost ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")


# --- 5. Hyperparameter Tuning ‡∏î‡πâ‡∏ß‡∏¢ GridSearchCV (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost 3.0.1) ---

print("\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Hyperparameters ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢ GridSearchCV...")

param_grid = {
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200], # n_estimators ‡πÉ‡∏ô GridSearch ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Early Stopping ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß
    'scale_pos_weight': [0.9, 1.0, 1.1]
}

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GridSearchCV ‡πÉ‡∏ô XGBoost 3.0.1+ ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ eval_metric ‡πÄ‡∏≠‡∏á‡∏à‡∏≤‡∏Å estimator
grid_search_xgb = GridSearchCV(
    estimator=xgb.XGBClassifier(
        objective='binary:logistic',
        # ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î eval_metric ‡∏ã‡πâ‡∏≥‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏ô estimator ‡πÅ‡∏•‡πâ‡∏ß
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42
    ),
    param_grid=param_grid,
    scoring='accuracy', # ‡πÄ‡∏ô‡πâ‡∏ô accuracy
    cv=3, # Cross-validation folds
    verbose=1, # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Grid Search
    n_jobs=-1 # ‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å core CPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
)

grid_search_xgb.fit(X_train, y_train)

print("‚úÖ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Hyperparameters ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")
print(f"‚ú® Best params: {grid_search_xgb.best_params_}")
print(f"üéØ Best accuracy (‡∏à‡∏≤‡∏Å CV): {grid_search_xgb.best_score_:.4f}")

best_model = grid_search_xgb.best_estimator_ # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Grid Search

# --- 6. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• RandomForestClassifier (‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ---
# ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (XGBoost) ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
print("\nüå≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• RandomForestClassifier (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Feature Importance)...")
model_rf = RandomForestClassifier(random_state=42, n_estimators=100)
model_rf.fit(X_train, y_train)
print("‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô RandomForestClassifier ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")

# --- 7. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Feature Importance ---

print("\nüìà ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...")

# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏à‡∏≤‡∏Å best_model (‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å XGBoost)
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:, 1] # ‡πÉ‡∏ä‡πâ best_model ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô

print(f"\nüìä F1 Score: {f1_score(y_test, y_pred):.4f}")
print(f"üìä ROC AUC: {roc_auc_score(y_test, y_prob):.4f}")
print("\nüìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nüìà Classification Report:\n", classification_report(y_test, y_pred))

# Feature Importance ‡∏à‡∏≤‡∏Å RandomForest (‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
print("\nüîç Feature Importance (‡∏à‡∏≤‡∏Å RandomForest):\n")
importances_rf = model_rf.feature_importances_
feature_importance_rf = pd.Series(importances_rf, index=features).sort_values(ascending=False)
print(feature_importance_rf)

# Feature Importance ‡∏à‡∏≤‡∏Å XGBoost (best_model)
print("\nüîç Feature Importance (‡∏à‡∏≤‡∏Å XGBoost Best Model):\n")
importances_xgb = best_model.feature_importances_
feature_importance_xgb = pd.Series(importances_xgb, index=features).sort_values(ascending=False)
print(feature_importance_xgb)


# --- 8. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ---

print("\nüîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ...")

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
# ‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î 3-4 ‡πÅ‡∏ó‡πà‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö lag features
# ‡∏î‡∏∂‡∏á‡πÄ‡∏ú‡∏∑‡πà‡∏≠ MA/RSI/BB ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 20 ‡πÅ‡∏ó‡πà‡∏á (‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤)
required_bars = max(20, 14, 3) + 1 # max period + 1 for current bar
latest_rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, required_bars)

if latest_rates is None or len(latest_rates) < required_bars:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢.")
    mt5.shutdown()
    exit()

latest_df = pd.DataFrame(latest_rates)
latest_df['Date'] = pd.to_datetime(latest_df['time'], unit='s')
latest_df = latest_df[['Date', 'open', 'high', 'low', 'close', 'tick_volume']]
latest_df.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
latest_df.set_index('Date', inplace=True)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô)
# MA (Moving Averages)
latest_df['MA5'] = latest_df['Close'].rolling(5).mean()
latest_df['MA10'] = latest_df['Close'].rolling(10).mean()
latest_df['MA20'] = latest_df['Close'].rolling(20).mean()

# RSI (Relative Strength Index)
delta_latest = latest_df['Close'].diff()
gain_latest = delta_latest.where(delta_latest > 0, 0.0)
loss_latest = -delta_latest.where(delta_latest < 0, 0.0)
avg_gain_latest = gain_latest.rolling(window=14).mean()
avg_loss_latest = loss_latest.rolling(window=14).mean()
with np.errstate(divide='ignore', invalid='ignore'):
    rs_latest = avg_gain_latest / avg_loss_latest
    latest_df['RSI'] = 100 - (100 / (1 + rs_latest))
latest_df['RSI'].replace([np.inf, -np.inf], np.nan, inplace=True)

# Bollinger Bands
latest_df['BB_Middle'] = latest_df['Close'].rolling(20).mean()
latest_df['BB_Std'] = latest_df['Close'].rolling(20).std()
latest_df['BB_Upper'] = latest_df['BB_Middle'] + 2 * latest_df['BB_Std']
latest_df['BB_Lower'] = latest_df['BB_Middle'] - 2 * latest_df['BB_Std']

# MACD (Moving Average Convergence Divergence)
ema12_latest = latest_df['Close'].ewm(span=12, adjust=False).mean()
ema26_latest = latest_df['Close'].ewm(span=26, adjust=False).mean()
latest_df['MACD'] = ema12_latest - ema26_latest
latest_df['MACD_Signal'] = latest_df['MACD'].ewm(span=9, adjust=False).mean()
latest_df['MACD_Diff'] = latest_df['MACD'] - latest_df['MACD_Signal']

# Lag features
for i in range(1, 4):
    latest_df[f'Close_lag{i}'] = latest_df['Close'].shift(i)

# Price Change
latest_df['Price_Change'] = latest_df['Close'] - latest_df['Close_lag1']
latest_df['Price_Change_Pct'] = latest_df['Price_Change'] / latest_df['Close_lag1']

# Bollinger Band Width
latest_df['BB_Width'] = latest_df['BB_Upper'] - latest_df['BB_Lower']
latest_df['Candle_Range'] = latest_df['High'] - latest_df['Low']

# Volume Spike
latest_df['Volume_MA10'] = latest_df['Volume'].rolling(window=10).mean()
latest_df['Volume_Spike'] = latest_df['Volume'] / latest_df['Volume_MA10']
latest_df['Volume_Change'] = latest_df['Volume'].pct_change()


# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô) - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ NaN
# ‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô dropna() ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
latest_df.dropna(inplace=True)
if latest_df.empty:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ (‡∏´‡∏•‡∏±‡∏á dropna).")
    mt5.shutdown()
    exit()

latest_features_row = latest_df[features].iloc[-1:].copy()

# Scale ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢ scaler ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô
latest_scaled = scaler.transform(latest_features_row)

# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
latest_pred_proba = best_model.predict_proba(latest_scaled)[0]
print(f"\nüîÆ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: ‡∏Ç‡∏∂‡πâ‡∏ô={latest_pred_proba[1]:.2%}, ‡∏•‡∏á={latest_pred_proba[0]:.2%}")

# ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
buy_threshold = 0.60
sell_threshold = 0.60

if latest_pred_proba[1] > buy_threshold:
    print("üü¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: BUY")
elif latest_pred_proba[0] > sell_threshold:
    print("üî¥ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: SELL")
else:
    print("‚ö™ ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô")

# --- ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MT5 ---
mt5.shutdown()
print("\n‚úÖ ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MT5 ‡πÅ‡∏•‡πâ‡∏ß.")