# FILE NAME: predict_BTCshortTradeV3.py
import pandas as pd
import numpy as np
import json
import os
import sys
import joblib # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å/‡πÇ‡∏´‡∏•‡∏î scaler ‡πÅ‡∏•‡∏∞ model
from datetime import datetime
import time # <-- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ import ‡πÇ‡∏°‡∏î‡∏π‡∏• 'time' ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤

# --- Global Configurations ---
# Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå MQL5\Files ‡∏Ç‡∏≠‡∏á MT5 Tester Agent (‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì!)
# !!! ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô Strategy Tester
# ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏´‡∏≤‡∏Å‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏Ç‡∏≠‡∏á MT5 Tester Agent ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ
FIXED_AGENT_FILES_PATH = "C:\\Users\\graze\\AppData\\Roaming\\MetaQuotes\\Tester\\53785E099C927DB68A545C249CDBCE06\\Agent-127.0.0.1-3000\\MQL5\\Files" # <-- ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ô‡∏µ‡πâ!

INPUT_DATA_FILE_NAME = "input_data.json"
OUTPUT_RESULT_FILE_NAME = "prediction_result.txt"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Full Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå Input ‡πÅ‡∏•‡∏∞ Output
input_file_path = os.path.join(FIXED_AGENT_FILES_PATH, INPUT_DATA_FILE_NAME)
output_file_path = os.path.join(FIXED_AGENT_FILES_PATH, OUTPUT_RESULT_FILE_NAME)

# Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•, Scaler, ‡πÅ‡∏•‡∏∞ Features List ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ
MODEL_PATH = 'xgboost_model_v6_no_symbol_features.pkl'
SCALER_PATH = 'scaler_v6_no_symbol_features.pkl'
FEATURES_LIST_PATH = 'features_list_v6_no_symbol_features.pkl' # This file should contain the list of features used during training

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå Input ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
LAST_INPUT_FILE_MOD_TIME = 0

# --- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•, Scaler, ‡πÅ‡∏•‡∏∞ Features List ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ ---
try:
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    features_list = joblib.load(FEATURES_LIST_PATH) # Load the exact features list used in training
    print(f"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost '{MODEL_PATH}' ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
    print(f"‚úÖ Scaler '{SCALER_PATH}' ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
    print(f"‚úÖ Features list '{FEATURES_LIST_PATH}' ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Features: {len(features_list)}")
except FileNotFoundError as e:
    print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô - {e}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•, scaler, ‡πÅ‡∏•‡∏∞ features list ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÑ‡∏î‡πÄ‡∏£‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ.")
    sys.exit() # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå
except Exception as e:
    print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö: {e}")
    sys.exit(1) # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏≠‡∏∑‡πà‡∏ô


# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏£‡∏±‡∏ö Features ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡πâ‡∏ß) ---
def prepare_data_for_prediction(features_dict, expected_features_list):
    """
    ‡∏£‡∏±‡∏ö dictionary ‡∏Ç‡∏≠‡∏á features ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å MT5,
    ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame, ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á features, ‡πÅ‡∏•‡∏∞ Scale ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•.
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏à‡∏≤‡∏Å dictionary ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö (‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 1 ‡πÅ‡∏ñ‡∏ß)
    df_features = pd.DataFrame([features_dict])

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ features ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
    missing_features = [f for f in expected_features_list if f not in df_features.columns]
    if missing_features:
        raise ValueError(f"Features ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {missing_features}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Feature Engineering ‡πÉ‡∏ô EA.")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö features_list ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
    # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á features ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà scaler ‡πÅ‡∏•‡∏∞ model ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
    df_features_ordered = df_features[expected_features_list]

    # Scale Features
    scaled_features = scaler.transform(df_features_ordered)
    
    # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô DataFrame (1 ‡πÅ‡∏ñ‡∏ß) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ XGBoost ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ
    return pd.DataFrame(scaled_features, columns=expected_features_list)

# --- Main File Monitoring Loop ---
def main_file_monitor():
    global LAST_INPUT_FILE_MOD_TIME

    print(f"Python Prediction Service Started. Monitoring for '{input_file_path}'...")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not os.path.isdir(FIXED_AGENT_FILES_PATH):
        print(f"‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á FIXED_AGENT_FILES_PATH '{FIXED_AGENT_FILES_PATH}' ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á.")
        print("‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πÄ‡∏£‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MT5 Tester Agent ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì.")
        print("‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå.")

    # Initialize features_data_json outside the loop to ensure it's always defined
    features_data_json = "" 

    while True:
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ input_data.json ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if os.path.exists(input_file_path):
                current_modified_time = os.path.getmtime(input_file_path)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏î‡∏¢ EA)
                if current_modified_time > LAST_INPUT_FILE_MOD_TIME:
                    # ‡∏≠‡πà‡∏≤‡∏ô input_data.json ‡∏î‡πâ‡∏ß‡∏¢ encoding UTF-8
                    with open(input_file_path, 'r', encoding='utf-8') as f:
                        features_data_json = f.read()
                    
                    LAST_INPUT_FILE_MOD_TIME = current_modified_time # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                    
                    print(f"üìñ ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö Features ‡∏à‡∏≤‡∏Å MT5 (‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå '{INPUT_DATA_FILE_NAME}')...") 

                    # ‡πÅ‡∏õ‡∏•‡∏á JSON string ‡πÄ‡∏õ‡πá‡∏ô Python dictionary
                    features_dict = json.loads(features_data_json)

                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                    try:
                        input_features_df = prepare_data_for_prediction(features_dict, features_list)
                        print(f"DEBUG: Input features DataFrame shape for prediction: {input_features_df.shape}")
                        # print(f"DEBUG: Input features DataFrame columns: {input_features_df.columns.tolist()}") # Uncomment for detailed debug

                        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
                        # ‡πÉ‡∏ä‡πâ prediction_threshold ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
                        prediction_threshold = 0.40 
                        
                        y_pred_proba = model.predict_proba(input_features_df)[:, 1] # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á Class 1
                        pred_class = (y_pred_proba > prediction_threshold).astype(int)[0] # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
                        
                        result = {'prediction': int(pred_class), 'probability': float(y_pred_proba[0])}
                        print(f"‚ö° ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result}")

                    except ValueError as ve:
                        result = {'prediction': -1, 'probability': 0.0, 'error': str(ve)}
                        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {ve}")
                    except Exception as e:
                        result = {'prediction': -1, 'probability': 0.0, 'error': str(e)}
                        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {e}")
                    
                    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡∏á‡πÉ‡∏ô prediction_result.txt ‡∏î‡πâ‡∏ß‡∏¢ encoding UTF-8
                    with open(output_file_path, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False)    
                    print(f"‚úçÔ∏è ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡∏á‡πÉ‡∏ô '{OUTPUT_RESULT_FILE_NAME}': {result}")
                    
                    # ‡∏•‡∏ö input.json ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÉ‡∏´‡πâ EA ‡∏ß‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ
                    try:
                        os.remove(input_file_path)
                        print(f"üóëÔ∏è ‡∏•‡∏ö '{INPUT_DATA_FILE_NAME}' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")
                    except OSError as e:
                        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå input: {e}")
            
            time.sleep(0.01) # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å 10ms ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß

        except json.JSONDecodeError as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ JSON ‡∏à‡∏≤‡∏Å '{INPUT_DATA_FILE_NAME}': {e}. ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: '{features_data_json[:200]}...'")
            if os.path.exists(input_file_path):
                try:
                    os.remove(input_file_path)
                    print(f"üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå '{INPUT_DATA_FILE_NAME}' ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢.")
                except Exception as e_clean:
                    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå input ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡πÑ‡∏î‡πâ: {e_clean}")
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô Main Loop: {e}")
            if os.path.exists(input_file_path):
                try:
                    os.remove(input_file_path)
                    print(f"üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå '{INPUT_DATA_FILE_NAME}' ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î.")
                except Exception as e_clean:
                    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå input ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÑ‡∏î‡πâ: {e_clean}")


if __name__ == '__main__':
    main_file_monitor() # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
