# FILE NAME: predict_LSTMTrade.py
# ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏•‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö MT5 ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå

import pandas as pd
import numpy as np
import json
import os
import sys
import joblib 
from datetime import datetime
import time 

# Import TensorFlow and Keras
import tensorflow as tf
from tensorflow.keras.models import load_model 

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ (Configuration) ---
# !!! ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå MQL5/Files ‡∏Ç‡∏≠‡∏á MT5 Tester Agent ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì !!!
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: C:\Users\graze\AppData\Roaming\MetaQuotes\Tester\53785E099C927DB68A545C249CDBCE06\Agent-127.0.0.1-3000\MQL5\Files
FIXED_AGENT_FILES_PATH = "C:\\Users\\graze\\AppData\\Roaming\\MetaQuotes\\Tester\\53785E099C927DB68A545C249CDBCE06\\Agent-127.0.0.1-3000\\MQL5\\Files" 

INPUT_DATA_FILE_NAME = "input_data.json"
OUTPUT_RESULT_FILE_NAME = "prediction_result.txt"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Full Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå Input ‡πÅ‡∏•‡∏∞ Output
input_file_path = os.path.join(FIXED_AGENT_FILES_PATH, INPUT_DATA_FILE_NAME)
output_file_path = os.path.join(FIXED_AGENT_FILES_PATH, OUTPUT_RESULT_FILE_NAME)

# Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•, Scaler, ‡πÅ‡∏•‡∏∞ Features List ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ
# !!! ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ
MODEL_PATH = './models/lstm_forextrader_modelV1.keras' # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
SCALER_PATH = './scaler_lstmV1.pkl' # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Scaler
FEATURES_LIST_PATH = './features_list_lstmV1.pkl' # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Features List
CLASS_WEIGHTS_PATH = './class_weights_lstmV1.pkl' # ‡πÄ‡∏û‡∏¥‡πà‡∏° Class Weights Path

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Scaler ---
def load_resources():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM, MinMaxScaler ‡πÅ‡∏•‡∏∞ Features List ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ"""
    try:
        model = load_model(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        features_list = joblib.load(FEATURES_LIST_PATH)
        
        # ‡πÇ‡∏´‡∏•‡∏î class_weights (‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå)
        class_weights = joblib.load(CLASS_WEIGHTS_PATH)
        
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•, Scaler, Features List ‡πÅ‡∏•‡∏∞ Class Weights ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")
        return model, scaler, features_list, class_weights
    except Exception as e:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£: {e}")
        print(f"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á:\n- {MODEL_PATH}\n- {SCALER_PATH}\n- {FEATURES_LIST_PATH}\n- {CLASS_WEIGHTS_PATH}")
        sys.exit(1) # ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏´‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì ---
def predict_signal(model, scaler, features_list, input_data_df, lookback_period=60):
    """
    ‡∏£‡∏±‡∏ö DataFrame ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Features ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (Lookback_Period ‡πÅ‡∏ó‡πà‡∏á)
    ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    """
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ input_data_df ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    missing_features = [f for f in features_list if f not in input_data_df.columns]
    if missing_features:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Input ‡∏Ç‡∏≤‡∏î Features ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {missing_features}")
        return "ERROR: Missing Features"

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
    # ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö scaler
    features_raw = input_data_df[features_list].values
    
    # Scale ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Features
    # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å scaler ‡∏ñ‡∏π‡∏Å fit ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2D (samples, features)
    # ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á 2D ‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ
    features_scaled = scaler.transform(features_raw)

    # ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö LSTM (Samples, Timesteps, Features)
    # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤ input_data_df ‡∏°‡∏µ Lookback_Period ‡πÅ‡∏ó‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
    # ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô samples = 1, timesteps = lookback_period, features = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features
    # features_scaled.shape ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô (lookback_period, num_features)
    # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô (1, lookback_period, num_features)
    
    if features_scaled.shape[0] != lookback_period:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô Input ({features_scaled.shape[0]}) ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö LOOKBACK_PERIOD ({lookback_period})")
        return "ERROR: Invalid Input Length"

    X_predict = features_scaled.reshape(1, lookback_period, features_scaled.shape[1])

    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô probabilities ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™)
    raw_prediction = model.predict(X_predict) # ‡∏à‡∏∞‡πÑ‡∏î‡πâ array ‡πÄ‡∏ä‡πà‡∏ô [[0.1, 0.8, 0.1]]

    # ‡∏´‡∏≤ Class ‡∏ó‡∏µ‡πà‡∏°‡∏µ Probability ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    predicted_class = np.argmax(raw_prediction, axis=1)[0] # ‡πÑ‡∏î‡πâ 0, 1, ‡∏´‡∏£‡∏∑‡∏≠ 2

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì
    # 0: Sell, 1: Buy, 2: Neutral
    if predicted_class == 1:
        signal = "BUY"
    elif predicted_class == 0:
        signal = "SELL"
    else: # predicted_class == 2
        signal = "NEUTRAL"
        
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: Raw probabilities: {raw_prediction[0]}, Predicted Class: {predicted_class} -> Signal: {signal}")
    return signal

# --- Main Loop ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö EA ---
def main():
    # ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    model, scaler, features_list, class_weights = load_resources()

    print(f"‚úÖ ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏≠‡πÑ‡∏ü‡∏•‡πå Input ‡∏ó‡∏µ‡πà: {input_file_path}")

    last_checked_time = 0

    while True:
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå input_data.json ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if os.path.exists(input_file_path):
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                current_file_mtime = os.path.getmtime(input_file_path)

                if current_file_mtime > last_checked_time:
                    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON
                    with open(input_file_path, 'r', encoding='utf-8') as f:
                        features_data_json = f.read()
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á JSON ‡πÄ‡∏õ‡πá‡∏ô DataFrame
                    features_data_list = json.loads(features_data_json)
                    features_data_df = pd.DataFrame(features_data_list)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'time' ‡πÄ‡∏õ‡πá‡∏ô datetime ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô index
                    features_data_df['time'] = pd.to_datetime(features_data_df['time'], unit='s') # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ EA ‡∏™‡πà‡∏á timestamp ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                    features_data_df = features_data_df.set_index('time')

                    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì
                    # LOOKBACK_PERIOD ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏ä‡πà‡∏ô 60)
                    # ‡∏ã‡∏∂‡πà‡∏á EA ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤ 60 ‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏û‡∏≠‡∏î‡∏µ
                    predicted_signal = predict_signal(model, scaler, features_list, features_data_df, lookback_period=60)

                    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå output_result.txt
                    with open(output_file_path, 'w', encoding='utf-8') as f:
                        f.write(predicted_signal)
                    
                    print(f"üöÄ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå '{predicted_signal}' ‡πÑ‡∏õ‡∏¢‡∏±‡∏á '{OUTPUT_RESULT_FILE_NAME}' ‡πÅ‡∏•‡πâ‡∏ß")

                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                    last_checked_time = current_file_mtime
                    
                    # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå Input ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ EA ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ
                    try:
                        os.remove(input_file_path)
                        print(f"üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå '{INPUT_DATA_FILE_NAME}' ‡πÅ‡∏•‡πâ‡∏ß")
                    except Exception as e:
                        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå input: {e}. ‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡∏•‡πá‡∏≠‡∏Å‡πÇ‡∏î‡∏¢‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô.")
            
            time.sleep(0.01) # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å 10ms ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß

        except json.JSONDecodeError as e:
            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå JSON ‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢ (‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå)
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ JSON ‡∏à‡∏≤‡∏Å '{INPUT_DATA_FILE_NAME}': {e}. ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: '{features_data_json[:200]}...'")
            # if os.path.exists(input_file_path):
            #     try:
            #         #os.remove(input_file_path)
            #         print(f"üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå '{INPUT_DATA_FILE_NAME}' ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ EA ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡∏°‡πà.")
            #     except Exception as e_clean:
            #         print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå input ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡πÑ‡∏î‡πâ: {e_clean}")
            time.sleep(0.1) # ‡∏û‡∏±‡∏Å‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
        except Exception as e:
            # ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÉ‡∏ô Main Loop
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô Main Loop: {e}")
            if os.path.exists(input_file_path):
                try:
                    os.remove(input_file_path)
                    print(f"üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå '{INPUT_DATA_FILE_NAME}' ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ EA ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡∏°‡πà.")
                except Exception as e_clean:
                    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå input ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡πÑ‡∏î‡πâ: {e_clean}")
            time.sleep(1) # ‡∏û‡∏±‡∏Å‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î


if __name__ == "__main__":
    main()
